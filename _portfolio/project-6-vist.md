---
title: "Robust Wearable Visual-Inertial Hand Motion Tracking Interface"
excerpt: "Robust hand tracking system fusing complementary strengths of visual and inertial sensors. The system addresses limitations of individual sensing modalities and provides an effective solution for Human-Robot Interaction (HRI) interfaces.<img src='/images/vist.png'>"
collection: project
---

<br/><img src='/images/vist.png'><br/>

Robust hand tracking system fusing complementary strengths of visual and inertial sensors. The system addresses limitations of individual sensing modalities and provides an effective solution for Human-Robot Interaction (HRI) interfaces.

* **Motivation**
    * Vision-based tracking systems face challenges such as occlusion and dependence on extensive datasets.
    * Wearable-based tracking systems are limited by issues like magnetic interference, lack of global position tracking, and the need for frequent and cumbersome calibration due to sensor bias.
* **Contributions**
    * Developed a filtering-based state estimation algorithm that opportunistically integrates visual and inertial sensor data.
    * Achieved a robust hand tracking system by leveraging the complementary properties of visual and inertial sensors, making it suitable for HRI interfaces.
* **Skills**:
    * Computer Vision, Inertial Measurement Unit (IMU), Extended Kalman Filter (EKF).
